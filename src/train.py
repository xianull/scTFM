import pyrootutils
import torch.multiprocessing as mp
import torch
import os
import json
import tempfile
from pathlib import Path

root = pyrootutils.setup_root(
    search_from=__file__,
    indicator=[".git", "requirements.txt"],
    pythonpath=True,
    dotenv=True,
)

import hydra
import wandb
from omegaconf import DictConfig, OmegaConf
import pytorch_lightning as pl
from pytorch_lightning import Callback, LightningDataModule, LightningModule, Trainer
from pytorch_lightning.loggers import Logger
from pytorch_lightning.loggers.wandb import WandbLogger
from typing import List, Optional

from src.utils.pylogger import get_pylogger
from src.utils.dataset_stats_utils import get_dataset_stats

log = get_pylogger(__name__)


def log_hyperparameters_to_wandb(
    cfg: DictConfig,
    loggers: List[Logger],
) -> None:
    """å°†Hydraé…ç½®è®°å½•åˆ°WandBã€‚"""
    wandb_logger: Optional[WandbLogger] = None
    for logger in loggers:
        if isinstance(logger, WandbLogger):
            wandb_logger = logger
            break

    if wandb_logger is None:
        log.warning("No WandbLogger found, skipping hyperparameter logging.")
        return

    experiment = wandb_logger.experiment
    if not hasattr(experiment, 'config') or not hasattr(experiment.config, 'update'):
        return

    hparams = {}
    config_keys = ["model", "data", "trainer", "callbacks", "task_name", "seed", "train", "test"]
    for key in config_keys:
        if key in cfg:
            value = cfg[key]
            if OmegaConf.is_config(value):
                hparams[key] = OmegaConf.to_container(value, resolve=True)
            else:
                hparams[key] = value

    experiment.config.update(hparams, allow_val_change=True)
    log.info("Hyperparameters logged to WandB successfully.")

@hydra.main(version_base="1.3", config_path="../configs", config_name="train.yaml")
def main(cfg: DictConfig):
    # ---------------------------------------------------------------------------
    # [å…³é”®] ä½¿ç”¨æ–‡ä»¶ç¼“å­˜é¿å… DDP å¤šè¿›ç¨‹é‡å¤è®¡ç®—
    # ä¸»è¿›ç¨‹ï¼ˆspawn å‰ï¼‰è®¡ç®—å¹¶ä¿å­˜ï¼Œå­è¿›ç¨‹ï¼ˆspawn åï¼‰ç›´æ¥è¯»å–
    # ---------------------------------------------------------------------------
    
    if cfg.get("train"):
        import json
        import tempfile
        from pathlib import Path
        
        # è·å–å½“å‰è¿›ç¨‹çš„ Rank
        local_rank = int(os.environ.get("LOCAL_RANK", -1))
        rank = int(os.environ.get("RANK", -1))
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯ä¸»è¿›ç¨‹ï¼ˆspawn å‰ï¼šä¸¤ä¸ªéƒ½æ˜¯ -1ï¼›spawn åï¼šä¼šæœ‰å…·ä½“å€¼ï¼‰
        is_pre_ddp = (local_rank == -1 and rank == -1)
        
        try:
            data_dir = cfg.data.get("data_dir")
            batch_size = cfg.data.get("batch_size", 256)
            
            # è®¡ç®— World Size
            devices = cfg.trainer.get("devices")
            if devices == "auto":
                world_size = torch.cuda.device_count()
            elif isinstance(devices, (list, tuple)) or OmegaConf.is_list(devices):
                world_size = len(devices)
            elif isinstance(devices, int):
                world_size = devices
            elif isinstance(devices, str) and devices.isdigit():
                world_size = int(devices)
            else:
                if isinstance(devices, str) and "," in devices:
                    world_size = len(devices.split(","))
                else:
                    world_size = 1
            
            # ä½¿ç”¨æ•°æ®ç›®å½•çš„ hash ä½œä¸ºç¼“å­˜æ–‡ä»¶åï¼Œé¿å…ä¸åŒæ•°æ®é›†å†²çª
            cache_key = f"{data_dir}_{batch_size}_{world_size}".replace("/", "_")
            cache_file = Path(tempfile.gettempdir()) / f"scTFM_stats_{cache_key}.json"
            
            # è·å– DataLoader workers æ•°ï¼ˆç”¨äºè´Ÿè½½å‡è¡¡ï¼‰
            num_workers_per_gpu = cfg.data.get("num_workers", 16)
            
            if is_pre_ddp:
                # ä¸»è¿›ç¨‹ï¼šè®¡ç®—å¹¶ç¼“å­˜
                log.info(f"ğŸ“Š [Main Process] Calculating dataset stats (World Size={world_size})...")
                
                from src.utils.dataset_stats_utils import balanced_shard_assignment
                
                total_cells, total_steps, shard_sizes = get_dataset_stats(
                    root_dir=data_dir,
                    split_label=0, 
                    batch_size=batch_size,
                    num_workers=16,  # åªæœ‰ä¸€ä¸ªè¿›ç¨‹è®¡ç®—ï¼Œå¯ä»¥å¼€å¤§
                    world_size=world_size,
                    num_workers_per_gpu=num_workers_per_gpu
                )
                
                # è®¡ç®—è´Ÿè½½å‡è¡¡çš„åˆ†é…æ–¹æ¡ˆ
                total_workers = world_size * num_workers_per_gpu
                assignment = balanced_shard_assignment(shard_sizes, total_workers)
                
                # ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
                cache_file.write_text(json.dumps({
                    "total_cells": total_cells,
                    "total_steps": total_steps,
                    "world_size": world_size,
                    "batch_size": batch_size,
                    "num_workers_per_gpu": num_workers_per_gpu,
                    "shard_sizes": shard_sizes,
                    "assignment": {str(k): v for k, v in assignment.items()}  # JSON keys must be strings
                }))
                
                log.info(f"âœ… [Main] Cached stats + assignment: {total_steps} steps â†’ {cache_file}")
                
            else:
                # DDP å­è¿›ç¨‹ï¼šè¯»å–ç¼“å­˜
                if cache_file.exists():
                    stats = json.loads(cache_file.read_text())
                    total_steps = stats["total_steps"]
                    log.info(f"ğŸ“¥ [Rank {local_rank}] Loaded from cache: {total_steps} steps")
                else:
                    log.warning(f"âš ï¸ [Rank {local_rank}] Cache not found, recalculating...")
                    from src.utils.dataset_stats_utils import balanced_shard_assignment
                    total_cells, total_steps, shard_sizes = get_dataset_stats(
                        root_dir=data_dir, split_label=0, 
                        batch_size=batch_size, num_workers=4, world_size=world_size,
                        num_workers_per_gpu=num_workers_per_gpu
                    )
            
            # è®¾ç½®é…ç½®
            if total_steps > 0:
                OmegaConf.set_struct(cfg, False)
                cfg.trainer.limit_train_batches = total_steps
                OmegaConf.set_struct(cfg, True)
                
        except Exception as e:
            log.warning(f"âŒ Failed to handle dataset stats: {e}")

    # ---------------------------------------------------------------------------
    # [Hydra/Lightning åˆå§‹åŒ–]
    # ---------------------------------------------------------------------------

    # 1. Seed
    if cfg.get("seed"):
        pl.seed_everything(cfg.seed, workers=True)

    # 2. DataModule
    log.info(f"Instantiating datamodule <{cfg.data._target_}>")
    
    # å¦‚æœæœ‰ç¼“å­˜çš„è´Ÿè½½å‡è¡¡æ–¹æ¡ˆï¼Œæ³¨å…¥åˆ° DataModule
    if cfg.get("train"):
        try:
            data_dir = cfg.data.get("data_dir")
            batch_size = cfg.data.get("batch_size", 256)
            devices = cfg.trainer.get("devices")
            
            if devices == "auto":
                world_size = torch.cuda.device_count()
            elif isinstance(devices, (list, tuple)) or OmegaConf.is_list(devices):
                world_size = len(devices)
            elif isinstance(devices, int):
                world_size = devices
            elif isinstance(devices, str) and devices.isdigit():
                world_size = int(devices)
            else:
                if isinstance(devices, str) and "," in devices:
                    world_size = len(devices.split(","))
                else:
                    world_size = 1
            
            cache_key = f"{data_dir}_{batch_size}_{world_size}".replace("/", "_")
            cache_file = Path(tempfile.gettempdir()) / f"scTFM_stats_{cache_key}.json"
            
            if cache_file.exists():
                stats = json.loads(cache_file.read_text())
                if "assignment" in stats:
                    # æ³¨å…¥è´Ÿè½½å‡è¡¡æ–¹æ¡ˆåˆ°é…ç½®
                    # [CRITICAL] ä¿æŒå­—ç¬¦ä¸² keyï¼Œå› ä¸º Dataset æŸ¥æ‰¾æ—¶ç”¨ str(global_worker_id)
                    OmegaConf.set_struct(cfg, False)
                    cfg.data.shard_assignment = stats["assignment"]  # ä¿æŒåŸå§‹å­—ç¬¦ä¸² key
                    OmegaConf.set_struct(cfg, True)
                    log.info(f"ğŸ“¥ Loaded shard assignment from cache ({len(stats['assignment'])} workers)")
        except Exception as e:
            log.warning(f"Failed to load shard assignment: {e}")
    
    datamodule: LightningDataModule = hydra.utils.instantiate(cfg.data)

    # 4. Model
    log.info(f"Instantiating model <{cfg.model._target_}>")
    model: LightningModule = hydra.utils.instantiate(cfg.model)

    # 5. Callbacks
    callbacks: List[Callback] = []
    if cfg.get("callbacks"):
        for _, cb_conf in cfg.callbacks.items():
            if "_target_" in cb_conf:
                callbacks.append(hydra.utils.instantiate(cb_conf))

    # 6. Logger
    logger: List[Logger] = []
    if cfg.get("logger"):
        for _, lg_conf in cfg.logger.items():
            if "_target_" in lg_conf:
                logger.append(hydra.utils.instantiate(lg_conf))

    if logger:
        log_hyperparameters_to_wandb(cfg, logger)

    # 7. Trainer
    log.info(f"Instantiating trainer <{cfg.trainer._target_}>")
    trainer: Trainer = hydra.utils.instantiate(
        cfg.trainer,
        callbacks=callbacks,
        logger=logger,
    )

    # 8. Train
    if cfg.get("train"):
        log.info("Starting training!")
        trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))

    # 9. Test
    if cfg.get("test"):
        log.info("Starting testing!")
        ckpt_path = trainer.checkpoint_callback.best_model_path
        if ckpt_path == "":
            log.warning("Best ckpt not found! Using current weights for testing...")
            ckpt_path = None
        trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)

    wandb.finish()

if __name__ == "__main__":
    # [å…³é”®] å¿…é¡»è®¾ç½®ä¸º spawnï¼Œå¦åˆ™ ProcessPoolExecutor å’Œ Lightning DDP éƒ½ä¼šå‡ºé—®é¢˜
    mp.set_start_method('spawn', force=True)
    main()

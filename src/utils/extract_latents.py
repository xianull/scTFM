#!/usr/bin/env python
"""
æå– Latent è¡¨ç¤ºè„šæœ¬

åŠŸèƒ½ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„ AE æ¨¡å‹
2. è¯»å– TileDB-SOMA æ•°æ®
3. é€šè¿‡ AE ç¼–ç åˆ° Latent Space
4. å°† Latent å‘é‡å­˜å‚¨åˆ°æ–°çš„ TileDB-SOMAï¼ˆä¿ç•™ obs å…ƒæ•°æ®ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/extract_latents.py \
    --ckpt_path logs/ae_stage1/checkpoints/best.ckpt \
    --input_dir /fast/data/scTFM/rtf/TEDD/tile_4000_fix \
    --output_dir /fast/data/scTFM/rtf/TEDD/latents \
    --batch_size 2048
"""

import os
import argparse
import shutil
from tqdm import tqdm
import multiprocessing

try:
    multiprocessing.set_start_method('spawn', force=True)
except RuntimeError:
    pass

import torch
import numpy as np
import tiledbsoma
import tiledbsoma.io
import anndata as ad
import pandas as pd
import scipy.sparse

from src.models.ae_module import AELitModule


def extract_latents_from_shard(
    shard_uri: str,
    output_uri: str,
    encoder,
    device: torch.device,
    batch_size: int = 2048,
    measurement_name: str = "RNA"
):
    """
    ä»å•ä¸ª shard æå– latent è¡¨ç¤ºã€‚
    
    Args:
        shard_uri: è¾“å…¥ shard è·¯å¾„
        output_uri: è¾“å‡º shard è·¯å¾„
        encoder: AE ç¼–ç å™¨
        device: è®¡ç®—è®¾å¤‡
        batch_size: æ‰¹æ¬¡å¤§å°
        measurement_name: æµ‹é‡åç§°
    """
    print(f"ğŸ“¦ Processing: {os.path.basename(shard_uri)}")
    
    try:
        # 1. è¯»å–åŸå§‹æ•°æ®
        ctx = tiledbsoma.SOMATileDBContext()
        with tiledbsoma.Experiment.open(shard_uri, context=ctx) as exp:
            # è¯»å– obsï¼ˆåŒ…å«æ‰€æœ‰å…ƒæ•°æ®ï¼šnext_cell_id, prev_cell_id, time ç­‰ï¼‰
            obs = exp.obs.read().concat().to_pandas()
            
            # è¯»å– X æ•°æ®ï¼ˆåŸºå› è¡¨è¾¾ï¼‰
            X_raw = exp.ms[measurement_name].X[measurement_name].read().tables().concat()
            X_raw = X_raw.to_pandas().to_numpy()
            
            if X_raw.shape[0] == 0:
                print(f"âš ï¸  Skipped: {shard_uri} (empty)")
                return False
        
        # 2. æ‰¹é‡ç¼–ç åˆ° Latent Space
        n_cells = X_raw.shape[0]
        n_batches = (n_cells + batch_size - 1) // batch_size
        
        latents = []
        
        for i in range(n_batches):
            start = i * batch_size
            end = min(start + batch_size, n_cells)
            
            # è½¬æ¢ä¸º Tensor
            X_batch = torch.from_numpy(X_raw[start:end]).float().to(device)
            
            # ç¼–ç 
            with torch.no_grad():
                z_batch = encoder(X_batch)
            
            latents.append(z_batch.cpu().numpy())
        
        # åˆå¹¶æ‰€æœ‰ batch
        X_latent = np.concatenate(latents, axis=0)
        
        # 3. åˆ›å»ºæ–°çš„ AnnDataï¼ˆlatent + å…ƒæ•°æ®ï¼‰
        adata_latent = ad.AnnData(
            X=scipy.sparse.csr_matrix(X_latent.astype(np.float32)),
            obs=obs  # ä¿ç•™æ‰€æœ‰å…ƒæ•°æ®ï¼
        )
        
        # æ·»åŠ  var_namesï¼ˆlatent ç»´åº¦ï¼‰
        latent_dim = X_latent.shape[1]
        adata_latent.var_names = [f"latent_{i}" for i in range(latent_dim)]
        
        # 4. å†™å…¥æ–°çš„ TileDB-SOMA
        if os.path.exists(output_uri):
            shutil.rmtree(output_uri)
        
        tiledbsoma.io.from_anndata(
            experiment_uri=output_uri,
            anndata=adata_latent,
            measurement_name=measurement_name
        )
        
        print(f"âœ… Saved: {os.path.basename(output_uri)} ({n_cells} cells, latent_dim={latent_dim})")
        return True
        
    except Exception as e:
        print(f"âŒ Error processing {shard_uri}: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="æå– Latent è¡¨ç¤º")
    parser.add_argument("--ckpt_path", type=str, required=True, help="AE æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--input_dir", type=str, required=True, help="è¾“å…¥ TileDB æ ¹ç›®å½•")
    parser.add_argument("--output_dir", type=str, required=True, help="è¾“å‡º Latent TileDB æ ¹ç›®å½•")
    parser.add_argument("--batch_size", type=int, default=2048, help="ç¼–ç æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--measurement_name", type=str, default="RNA", help="Measurement åç§°")
    parser.add_argument("--device", type=str, default=None, help="è®¡ç®—è®¾å¤‡ (cuda:0, cpu, auto)")
    
    args = parser.parse_args()
    
    # 1. æ£€æŸ¥è¾“å…¥è·¯å¾„
    if not os.path.exists(args.input_dir):
        raise ValueError(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input_dir}")
    
    # 2. åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # 3. åŠ è½½ AE æ¨¡å‹
    print(f"ğŸ”§ åŠ è½½ AE æ¨¡å‹: {args.ckpt_path}")
    
    if args.device is None or args.device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(args.device)
    
    ae_model = AELitModule.load_from_checkpoint(args.ckpt_path, map_location=device)
    ae_model.eval()
    ae_model.to(device)
    
    # è·å–ç¼–ç å™¨
    encoder = ae_model.net.encode
    
    print(f"âœ… AE æ¨¡å‹å·²åŠ è½½åˆ° {device}")
    
    # 4. æ‰«ææ‰€æœ‰ shards
    shard_dirs = sorted([
        d for d in os.listdir(args.input_dir)
        if os.path.isdir(os.path.join(args.input_dir, d))
    ])
    
    print(f"ğŸ“Š å‘ç° {len(shard_dirs)} ä¸ª shards")
    
    # 5. é€ä¸ªå¤„ç† shards
    success_count = 0
    
    for shard_name in tqdm(shard_dirs, desc="æå– Latent"):
        input_shard_uri = os.path.join(args.input_dir, shard_name)
        output_shard_uri = os.path.join(args.output_dir, shard_name)
        
        success = extract_latents_from_shard(
            shard_uri=input_shard_uri,
            output_uri=output_shard_uri,
            encoder=encoder,
            device=device,
            batch_size=args.batch_size,
            measurement_name=args.measurement_name
        )
        
        if success:
            success_count += 1
    
    # 6. æ€»ç»“
    print("\n" + "=" * 50)
    print(f"âœ… å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(shard_dirs)} ä¸ª shards")
    print(f"ğŸ“‚ Latent æ•°æ®ä¿å­˜åˆ°: {args.output_dir}")
    print("=" * 50)
    
    # 7. éªŒè¯è¾“å‡º
    print("\néªŒè¯è¾“å‡º...")
    output_shards = sorted([
        d for d in os.listdir(args.output_dir)
        if os.path.isdir(os.path.join(args.output_dir, d))
    ])
    
    if len(output_shards) > 0:
        # è¯»å–ç¬¬ä¸€ä¸ª shard éªŒè¯ç»“æ„
        test_uri = os.path.join(args.output_dir, output_shards[0])
        ctx = tiledbsoma.SOMATileDBContext()
        
        with tiledbsoma.Experiment.open(test_uri, context=ctx) as exp:
            obs = exp.obs.read().concat().to_pandas()
            latent_dim = exp.ms[args.measurement_name].var.count
            
            print(f"\nğŸ“‹ è¾“å‡ºæ•°æ®ç»“æ„:")
            print(f"  - Latent Dim: {latent_dim}")
            print(f"  - Obs åˆ—: {list(obs.columns)}")
            print(f"  - åŒ…å« next_cell_id: {'next_cell_id' in obs.columns}")
            print(f"  - åŒ…å« prev_cell_id: {'prev_cell_id' in obs.columns}")
            print(f"  - åŒ…å« time: {'time' in obs.columns}")
    
    print("\nğŸ‰ Latent æå–å®Œæˆï¼ç°åœ¨å¯ä»¥è®­ç»ƒ RTF äº†ï¼š")
    print(f"python src/train.py -cn train_rtf \\")
    print(f"  model.mode=latent \\")
    print(f"  model.latent_dim={latent_dim} \\")
    print(f"  data.data_dir={args.output_dir}")


if __name__ == "__main__":
    main()


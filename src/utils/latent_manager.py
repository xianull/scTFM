"""
Latent æ•°æ®è‡ªåŠ¨ç®¡ç†æ¨¡å—

åŠŸèƒ½ï¼š
1. æ£€æµ‹ latent æ•°æ®æ˜¯å¦å­˜åœ¨
2. æ ¹æ® raw æ•°æ®ç›®å½•è‡ªåŠ¨æ¨ç† latent ç›®å½•è·¯å¾„
3. åœ¨éœ€è¦æ—¶è‡ªåŠ¨æå– latent

ä½¿ç”¨æ–¹å¼ï¼š
åœ¨ train.py ä¸­è°ƒç”¨ ensure_latent_data() å³å¯è‡ªåŠ¨å¤„ç†
"""

import os
import shutil
from pathlib import Path
from typing import Optional, Tuple, List, Dict
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp

import torch
import numpy as np
import tiledbsoma
import tiledbsoma.io
import anndata as ad
import scipy.sparse
from tqdm import tqdm

log = logging.getLogger(__name__)


def get_latent_dir(raw_data_dir: str, latent_suffix: str = "_latents") -> str:
    """
    æ ¹æ® raw æ•°æ®ç›®å½•æ¨ç† latent ç›®å½•è·¯å¾„ã€‚

    ç¤ºä¾‹ï¼š
        /fast/data/scTFM/rtf/TEDD/tile_4000_fix
        â†’ /fast/data/scTFM/rtf/TEDD/tile_4000_fix_latents

    Args:
        raw_data_dir: åŸå§‹ TileDB æ•°æ®ç›®å½•
        latent_suffix: latent ç›®å½•åç¼€ï¼ˆé»˜è®¤ "_latents"ï¼‰

    Returns:
        latent ç›®å½•è·¯å¾„
    """
    raw_path = Path(raw_data_dir).resolve()
    return str(raw_path.parent / f"{raw_path.name}{latent_suffix}")


def check_latent_exists(latent_dir: str, raw_data_dir: str) -> Tuple[bool, str]:
    """
    æ£€æŸ¥ latent æ•°æ®æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆã€‚

    éªŒè¯æ¡ä»¶ï¼š
    1. latent ç›®å½•å­˜åœ¨
    2. latent ç›®å½•ä¸‹æœ‰å­ç›®å½•ï¼ˆshardsï¼‰
    3. shard æ•°é‡ä¸ raw æ•°æ®ä¸€è‡´
    4. æ¯ä¸ª shard åŒ…å«æœ‰æ•ˆçš„ TileDB-SOMA ç»“æ„

    Args:
        latent_dir: latent æ•°æ®ç›®å½•
        raw_data_dir: åŸå§‹æ•°æ®ç›®å½•ï¼ˆç”¨äºéªŒè¯ shard æ•°é‡ï¼‰

    Returns:
        (is_valid, message)
    """
    latent_path = Path(latent_dir)
    raw_path = Path(raw_data_dir)

    # 1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not latent_path.exists():
        return False, f"Latent ç›®å½•ä¸å­˜åœ¨: {latent_dir}"

    # 2. è·å– shard åˆ—è¡¨
    latent_shards = sorted([
        d for d in os.listdir(latent_dir)
        if os.path.isdir(os.path.join(latent_dir, d))
    ])

    raw_shards = sorted([
        d for d in os.listdir(raw_data_dir)
        if os.path.isdir(os.path.join(raw_data_dir, d))
    ])

    if len(latent_shards) == 0:
        return False, f"Latent ç›®å½•ä¸ºç©º: {latent_dir}"

    # 3. æ£€æŸ¥ shard æ•°é‡æ˜¯å¦ä¸€è‡´
    if len(latent_shards) != len(raw_shards):
        return False, f"Shard æ•°é‡ä¸åŒ¹é…: latent={len(latent_shards)}, raw={len(raw_shards)}"

    # 4. æŠ½æ ·æ£€æŸ¥å‡ ä¸ª shard æ˜¯å¦æœ‰æ•ˆ
    sample_shards = latent_shards[:min(3, len(latent_shards))]
    ctx = tiledbsoma.SOMATileDBContext()

    for shard_name in sample_shards:
        shard_uri = os.path.join(latent_dir, shard_name)
        try:
            with tiledbsoma.Experiment.open(shard_uri, context=ctx) as exp:
                # æ£€æŸ¥æ˜¯å¦æœ‰ obs å’Œ X æ•°æ®
                obs = exp.obs.read().concat().to_pandas()
                if 'next_cell_id' not in obs.columns:
                    return False, f"Shard {shard_name} ç¼ºå°‘ next_cell_id åˆ—"
                if 'time' not in obs.columns:
                    return False, f"Shard {shard_name} ç¼ºå°‘ time åˆ—"
        except Exception as e:
            return False, f"Shard {shard_name} è¯»å–å¤±è´¥: {e}"

    return True, f"Latent æ•°æ®æœ‰æ•ˆ ({len(latent_shards)} shards)"


def extract_latents(
    raw_data_dir: str,
    latent_dir: str,
    ae_ckpt_path: str,
    batch_size: int = 2048,
    measurement_name: str = "RNA",
    device: Optional[str] = None,
    force: bool = False,
) -> bool:
    """
    ä»åŸå§‹æ•°æ®æå– latent è¡¨ç¤ºã€‚

    Args:
        raw_data_dir: åŸå§‹ TileDB æ•°æ®ç›®å½•
        latent_dir: è¾“å‡º latent ç›®å½•
        ae_ckpt_path: AE æ¨¡å‹ checkpoint è·¯å¾„
        batch_size: ç¼–ç æ‰¹æ¬¡å¤§å°
        measurement_name: æµ‹é‡åç§°
        device: è®¡ç®—è®¾å¤‡
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°æå–

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    from src.models.ae_module import AELitModule

    log.info("=" * 60)
    log.info("ğŸš€ è‡ªåŠ¨æå– Latent è¡¨ç¤º")
    log.info("=" * 60)
    log.info(f"  Raw æ•°æ®ç›®å½•: {raw_data_dir}")
    log.info(f"  Latent è¾“å‡ºç›®å½•: {latent_dir}")
    log.info(f"  AE Checkpoint: {ae_ckpt_path}")

    # 1. æ£€æŸ¥ AE checkpoint
    if not os.path.exists(ae_ckpt_path):
        log.error(f"âŒ AE checkpoint ä¸å­˜åœ¨: {ae_ckpt_path}")
        return False

    # 2. æ£€æŸ¥åŸå§‹æ•°æ®ç›®å½•
    if not os.path.exists(raw_data_dir):
        log.error(f"âŒ Raw æ•°æ®ç›®å½•ä¸å­˜åœ¨: {raw_data_dir}")
        return False

    # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶é‡æ–°æå–
    if os.path.exists(latent_dir) and not force:
        is_valid, msg = check_latent_exists(latent_dir, raw_data_dir)
        if is_valid:
            log.info(f"âœ… {msg}ï¼Œè·³è¿‡æå–")
            return True
        else:
            log.warning(f"âš ï¸ {msg}ï¼Œå°†é‡æ–°æå–")
            shutil.rmtree(latent_dir)

    # 4. åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(latent_dir, exist_ok=True)

    # 5. åŠ è½½ AE æ¨¡å‹ï¼ˆä» checkpoint æ—è¾¹çš„ hydra é…ç½®è¯»å– net ç»“æ„ï¼‰
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    device = torch.device(device)

    log.info(f"ğŸ”§ åŠ è½½ AE æ¨¡å‹åˆ° {device}...")

    # å°è¯•ä» .hydra/config.yaml è¯»å–æ¨¡å‹é…ç½®
    ckpt_dir = Path(ae_ckpt_path).parent.parent  # checkpoints/ -> run_dir/
    hydra_config_path = ckpt_dir / ".hydra" / "config.yaml"

    if hydra_config_path.exists():
        import yaml
        from omegaconf import OmegaConf
        import hydra

        log.info(f"ğŸ“„ ä» Hydra é…ç½®åŠ è½½ net ç»“æ„: {hydra_config_path}")
        with open(hydra_config_path, 'r') as f:
            saved_cfg = OmegaConf.create(yaml.safe_load(f))

        # å®ä¾‹åŒ– net
        net = hydra.utils.instantiate(saved_cfg.model.net)

        # åŠ è½½ checkpointï¼Œä¼ å…¥ net
        ae_model = AELitModule.load_from_checkpoint(
            ae_ckpt_path,
            map_location=device,
            net=net
        )
    else:
        # Fallback: ç›´æ¥åŠ è½½ï¼ˆå¯èƒ½éœ€è¦ checkpoint åŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
        log.warning(f"âš ï¸ æœªæ‰¾åˆ° Hydra é…ç½®ï¼Œå°è¯•ç›´æ¥åŠ è½½ checkpoint")
        ae_model = AELitModule.load_from_checkpoint(ae_ckpt_path, map_location=device)

    ae_model.eval()
    ae_model.to(device)
    encoder = ae_model.net.encode

    # 6. æ‰«ææ‰€æœ‰ shards
    shard_dirs = sorted([
        d for d in os.listdir(raw_data_dir)
        if os.path.isdir(os.path.join(raw_data_dir, d))
    ])

    log.info(f"ğŸ“Š å‘ç° {len(shard_dirs)} ä¸ª shards")

    # 7. å¹¶è¡Œå¤„ç† shardsï¼ˆæµæ°´çº¿ï¼šé¢„è¯»å– -> GPUç¼–ç  -> å†™å…¥ï¼‰
    success_count = 0
    latent_dim = None
    num_io_workers = min(4, len(shard_dirs))  # IO å¹¶è¡Œåº¦

    log.info(f"ğŸš€ ä½¿ç”¨ {num_io_workers} ä¸ª IO çº¿ç¨‹å¹¶è¡Œå¤„ç†")

    # é¢„è¯»å–é˜Ÿåˆ—
    prefetch_queue: List[Dict] = []
    max_prefetch = 4  # æœ€å¤šé¢„è¯»å– 4 ä¸ª shard

    def prefetch_shard(shard_name: str) -> Optional[Dict]:
        """é¢„è¯»å–å•ä¸ª shard çš„æ•°æ®ï¼ˆCPU æ“ä½œï¼‰"""
        input_uri = os.path.join(raw_data_dir, shard_name)
        output_uri = os.path.join(latent_dir, shard_name)

        try:
            ctx = tiledbsoma.SOMATileDBContext(tiledb_config={
                "py.init_buffer_bytes": 512 * 1024**2,
                "sm.memory_budget": 4 * 1024**3,
            })

            with tiledbsoma.Experiment.open(input_uri, context=ctx) as exp:
                obs = exp.obs.read().concat().to_pandas()
                n_cells = len(obs)
                n_vars = exp.ms[measurement_name].var.count

                if n_cells == 0:
                    return None

                x_uri = os.path.join(input_uri, "ms", measurement_name, "X", "data")

            with tiledbsoma.open(x_uri, mode='r', context=ctx) as X:
                data = X.read().tables().concat()
                row_indices = data["soma_dim_0"].to_numpy()
                col_indices = data["soma_dim_1"].to_numpy()
                values = data["soma_data"].to_numpy()

            X_raw = np.zeros((n_cells, n_vars), dtype=np.float32)
            X_raw[row_indices, col_indices] = values

            return {
                "shard_name": shard_name,
                "input_uri": input_uri,
                "output_uri": output_uri,
                "X_raw": X_raw,
                "obs": obs,
            }
        except Exception as e:
            log.warning(f"âš ï¸ é¢„è¯»å– {shard_name} å¤±è´¥: {e}")
            return None

    def write_shard(data: Dict, X_latent: np.ndarray, latent_dim: int) -> bool:
        """å†™å…¥å•ä¸ª shard çš„ latent æ•°æ®ï¼ˆCPU æ“ä½œï¼‰"""
        try:
            adata_latent = ad.AnnData(
                X=scipy.sparse.csr_matrix(X_latent.astype(np.float32)),
                obs=data["obs"]
            )
            adata_latent.var_names = [f"latent_{i}" for i in range(latent_dim)]

            if os.path.exists(data["output_uri"]):
                shutil.rmtree(data["output_uri"])

            tiledbsoma.io.from_anndata(
                experiment_uri=data["output_uri"],
                anndata=adata_latent,
                measurement_name=measurement_name
            )
            return True
        except Exception as e:
            log.warning(f"âš ï¸ å†™å…¥ {data['shard_name']} å¤±è´¥: {e}")
            return False

    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œ IO å¹¶è¡Œ
    with ThreadPoolExecutor(max_workers=num_io_workers) as io_executor:
        # æäº¤æ‰€æœ‰é¢„è¯»å–ä»»åŠ¡
        prefetch_futures = {
            io_executor.submit(prefetch_shard, shard_name): shard_name
            for shard_name in shard_dirs
        }

        # å†™å…¥ä»»åŠ¡é˜Ÿåˆ—
        write_futures = []

        # æµæ°´çº¿å¤„ç†
        pbar = tqdm(total=len(shard_dirs), desc="æå– Latent")

        for future in as_completed(prefetch_futures):
            shard_name = prefetch_futures[future]
            try:
                data = future.result()
                if data is None:
                    pbar.update(1)
                    continue

                # GPU ç¼–ç ï¼ˆä¸²è¡Œï¼Œé¿å… GPU ç«äº‰ï¼‰
                X_raw = data["X_raw"]
                n_cells = X_raw.shape[0]
                n_batches = (n_cells + batch_size - 1) // batch_size

                latents = []
                for i in range(n_batches):
                    start = i * batch_size
                    end = min(start + batch_size, n_cells)
                    X_batch = torch.from_numpy(X_raw[start:end]).float().to(device)

                    with torch.no_grad():
                        z_batch = encoder(X_batch)
                    latents.append(z_batch.cpu().numpy())

                X_latent = np.concatenate(latents, axis=0)
                current_latent_dim = X_latent.shape[1]

                if latent_dim is None:
                    latent_dim = current_latent_dim

                # é‡Šæ”¾åŸå§‹æ•°æ®å†…å­˜
                del data["X_raw"]

                # å¼‚æ­¥å†™å…¥
                write_future = io_executor.submit(write_shard, data, X_latent, latent_dim)
                write_futures.append((write_future, shard_name))

                pbar.update(1)

            except Exception as e:
                log.warning(f"âš ï¸ å¤„ç† {shard_name} å¤±è´¥: {e}")
                pbar.update(1)

        pbar.close()

        # ç­‰å¾…æ‰€æœ‰å†™å…¥å®Œæˆ
        log.info("â³ ç­‰å¾…å†™å…¥å®Œæˆ...")
        for write_future, shard_name in tqdm(write_futures, desc="å†™å…¥ Shard"):
            try:
                if write_future.result():
                    success_count += 1
            except Exception as e:
                log.warning(f"âš ï¸ å†™å…¥ {shard_name} å¤±è´¥: {e}")

    # 8. æ€»ç»“
    log.info("=" * 60)
    log.info(f"âœ… Latent æå–å®Œæˆï¼")
    log.info(f"   æˆåŠŸ: {success_count}/{len(shard_dirs)} shards")
    log.info(f"   Latent ç»´åº¦: {latent_dim}")
    log.info(f"   è¾“å‡ºç›®å½•: {latent_dir}")
    log.info("=" * 60)

    return success_count == len(shard_dirs)


def ensure_latent_data(
    mode: str,
    raw_data_dir: str,
    ae_ckpt_path: Optional[str] = None,
    latent_dir: Optional[str] = None,
    batch_size: int = 2048,
    device: Optional[str] = None,
) -> str:
    """
    ç¡®ä¿ latent æ•°æ®å¯ç”¨ï¼Œè¿”å›å®é™…çš„ data_dirã€‚

    è¿™æ˜¯ä¾› train.py è°ƒç”¨çš„ä¸»å…¥å£å‡½æ•°ã€‚

    Args:
        mode: è®­ç»ƒæ¨¡å¼ ("latent" æˆ– "raw")
        raw_data_dir: åŸå§‹ TileDB æ•°æ®ç›®å½•
        ae_ckpt_path: AE checkpoint è·¯å¾„ï¼ˆlatent æ¨¡å¼å¿…éœ€ï¼‰
        latent_dir: æŒ‡å®šçš„ latent ç›®å½•ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ¨ç†ï¼‰
        batch_size: æå–æ—¶çš„æ‰¹æ¬¡å¤§å°
        device: è®¡ç®—è®¾å¤‡

    Returns:
        å®é™…ä½¿ç”¨çš„ data_dir è·¯å¾„

    Raises:
        ValueError: é…ç½®é”™è¯¯æ—¶æŠ›å‡º
    """
    # Raw æ¨¡å¼ï¼šç›´æ¥è¿”å›åŸå§‹æ•°æ®ç›®å½•
    if mode == "raw":
        if not os.path.exists(raw_data_dir):
            raise ValueError(f"Raw æ•°æ®ç›®å½•ä¸å­˜åœ¨: {raw_data_dir}")
        log.info(f"ğŸ“ [Raw Mode] ä½¿ç”¨åŸå§‹æ•°æ®: {raw_data_dir}")
        return raw_data_dir

    # Latent æ¨¡å¼
    if mode == "latent":
        # æ¨ç† latent ç›®å½•
        if latent_dir is None:
            latent_dir = get_latent_dir(raw_data_dir)

        log.info(f"ğŸ“ [Latent Mode] æ£€æŸ¥ Latent æ•°æ®...")
        log.info(f"   Raw ç›®å½•: {raw_data_dir}")
        log.info(f"   Latent ç›®å½•: {latent_dir}")

        # æ£€æŸ¥ latent æ•°æ®æ˜¯å¦å­˜åœ¨
        is_valid, msg = check_latent_exists(latent_dir, raw_data_dir)

        if is_valid:
            log.info(f"âœ… {msg}")
            return latent_dir

        # Latent ä¸å­˜åœ¨ï¼Œéœ€è¦æå–
        log.warning(f"âš ï¸ {msg}")

        # æ£€æŸ¥ AE checkpoint
        if ae_ckpt_path is None:
            raise ValueError(
                f"Latent æ•°æ®ä¸å­˜åœ¨ä¸”æœªæŒ‡å®š ae_ckpt_pathï¼\n"
                f"è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è§£å†³ï¼š\n"
                f"1. æ‰‹åŠ¨è¿è¡Œ: python src/utils/extract_latents.py --ckpt_path <AE_CKPT> --input_dir {raw_data_dir} --output_dir {latent_dir}\n"
                f"2. é…ç½® model.ae_ckpt_path å‚æ•°ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æå–"
            )

        if not os.path.exists(ae_ckpt_path):
            raise ValueError(f"AE checkpoint ä¸å­˜åœ¨: {ae_ckpt_path}")

        # è‡ªåŠ¨æå– latent
        log.info("ğŸš€ å¼€å§‹è‡ªåŠ¨æå– Latent...")
        success = extract_latents(
            raw_data_dir=raw_data_dir,
            latent_dir=latent_dir,
            ae_ckpt_path=ae_ckpt_path,
            batch_size=batch_size,
            device=device,
        )

        if not success:
            raise RuntimeError(f"Latent æå–å¤±è´¥ï¼è¯·æ£€æŸ¥æ—¥å¿—æˆ–æ‰‹åŠ¨æå–ã€‚")

        return latent_dir

    # æœªçŸ¥æ¨¡å¼
    raise ValueError(f"æœªçŸ¥çš„è®­ç»ƒæ¨¡å¼: {mode}ï¼Œæ”¯æŒ 'latent' æˆ– 'raw'")
